"""
–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è WB –∏ Ozon –Ω–∞ Firefox
–°–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–∑–¥–∞–µ—Ç product.json –∏ reviews.json
"""

import asyncio
import json
import re
import random
import logging
from typing import List, Dict, Any, Optional
from playwright.async_api import async_playwright

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class FirefoxMarketplaceParser:
    """–ü–∞—Ä—Å–µ—Ä –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤ –Ω–∞ Firefox"""
    
    def __init__(self):
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None
    
    async def human_delay(self, min_sec=2, max_sec=4):
        """–°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞"""
        delay = random.uniform(min_sec, max_sec)
        logger.info(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ {delay:.1f} —Å–µ–∫...")
        await asyncio.sleep(delay)
    
    async def setup_browser(self):
        """–ó–∞–ø—É—Å–∫ Firefox"""
        logger.info("ü¶ä –ó–∞–ø—É—Å–∫ Firefox...")
        
        self.playwright = await async_playwright().start()
        
        self.browser = await self.playwright.firefox.launch(
            headless=True  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ False –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        )
        
        self.context = await self.browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0",
            locale="ru-RU"
        )
        
        self.page = await self.context.new_page()
        self.page.set_default_timeout(30000)
        
        logger.info("‚úÖ Firefox –∑–∞–ø—É—â–µ–Ω")
    
    async def close_browser(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        logger.info("üîí –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
    
    def _extract_number(self, text: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å–ª–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return None
        cleaned = re.sub(r'[^\d]', '', text)
        return int(cleaned) if cleaned.isdigit() else None
    
    async def _get_text(self, selector: str, timeout: int = 5000) -> Optional[str]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"""
        try:
            await self.page.wait_for_selector(selector, timeout=timeout, state="visible")
            element = await self.page.query_selector(selector)
            if element:
                text = await element.text_content()
                return text.strip() if text else None
        except Exception as e:
            logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        return None
    
    async def parse_wildberries(self, url: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ Wildberries"""
        logger.info("="*60)
        logger.info(f"üõí –ü–ê–†–°–ò–ù–ì WILDBERRIES")
        logger.info("="*60)
        
        try:
            logger.info(f"üì¶ URL: {url}")
            await self.page.goto(url, wait_until="domcontentloaded", timeout=60000)
            await self.human_delay(3, 5)
            
            # ID —Ç–æ–≤–∞—Ä–∞
            product_id = url.split("/")[-2] if "/catalog/" in url else "unknown"
            logger.info(f"üÜî Product ID: {product_id}")
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ
            name_selectors = [
                "h1",
                ".product-page__title",
                "[data-link='text{:product-page/product-detail/header}']"
            ]
            name = None
            for selector in name_selectors:
                name = await self._get_text(selector)
                if name:
                    logger.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ: {name[:60]}...")
                    break
            
            if not name:
                name = "–¢–æ–≤–∞—Ä –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
                logger.warning("‚ö†Ô∏è –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
            # –¶–µ–Ω–∞
            price = None
            price_selectors = [
                ".price-block__final-price",
                "[class*='price-block__final']",
                ".product-page__price-block span"
            ]
            
            for selector in price_selectors:
                price_text = await self._get_text(selector)
                if price_text:
                    price = self._extract_number(price_text)
                    if price:
                        logger.info(f"üí∞ –¶–µ–Ω–∞: {price} ‚ÇΩ")
                        break
            
            if not price:
                logger.warning("‚ö†Ô∏è –¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            # –û–ø–∏—Å–∞–Ω–∏–µ
            description = ""
            desc_selectors = [
                ".product-page__description-text",
                "[class*='description']",
                ".collapsable__content p"
            ]
            
            for selector in desc_selectors:
                desc = await self._get_text(selector, timeout=3000)
                if desc and len(desc) > 20:
                    description = desc[:500]  # –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤
                    logger.info(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: {description[:60]}...")
                    break
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            characteristics = ""
            char_selectors = [
                ".product-params__table",
                "[class*='params']"
            ]
            
            for selector in char_selectors:
                chars = await self._get_text(selector, timeout=3000)
                if chars:
                    characteristics = chars[:500]
                    logger.info(f"üìä –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞–π–¥–µ–Ω—ã")
                    break
            
            # –û—Ç–∑—ã–≤—ã
            logger.info("üí¨ –°–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤...")
            reviews = await self._parse_wb_reviews(product_id)
            logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")
            
            return {
                "product": {
                    "id": f"wb_{product_id}",
                    "name": name,
                    "url": url,
                    "price": price,
                    "currency": "RUB",
                    "description": description,
                    "characteristics": characteristics
                },
                "reviews": reviews
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ WB: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    async def _parse_wb_reviews(self, product_id: str, max_reviews: int = 10) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ WB"""
        reviews = []
        
        try:
            # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–û—Ç–∑—ã–≤—ã" –∏ –∫–ª–∏–∫–∞–µ–º
            review_button_selectors = [
                "a[href*='#comments']",
                "button:has-text('–û—Ç–∑—ã–≤—ã')",
                "[data-link*='comments']"
            ]
            
            for selector in review_button_selectors:
                try:
                    button = await self.page.query_selector(selector)
                    if button:
                        await button.click()
                        logger.info("üîΩ –ü–µ—Ä–µ—Ö–æ–¥ –∫ –æ—Ç–∑—ã–≤–∞–º...")
                        await self.human_delay(2, 3)
                        break
                except:
                    continue
            
            # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–æ –æ—Ç–∑—ã–≤–æ–≤
            await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight / 2)")
            await self.human_delay(1, 2)
            
            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ—Ç–∑—ã–≤–æ–≤
            review_selectors = [
                ".comments__item",
                ".feedback__item",
                "[class*='comment']",
                "[class*='review']"
            ]
            
            elements = []
            for selector in review_selectors:
                elements = await self.page.query_selector_all(selector)
                if elements and len(elements) > 0:
                    logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ—Ç–∑—ã–≤–æ–≤: {len(elements)}")
                    break
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            for i, elem in enumerate(elements[:max_reviews]):
                try:
                    text = await elem.text_content()
                    if text and len(text.strip()) > 10:
                        reviews.append({
                            "id": f"wb_review_{i+1}",
                            "product_id": f"wb_{product_id}",
                            "text": text.strip()[:1000]  # –ú–∞–∫—Å–∏–º—É–º 1000 —Å–∏–º–≤–æ–ª–æ–≤
                        })
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–∞ {i}: {e}")
                    continue
            
            # –ï—Å–ª–∏ –æ—Ç–∑—ã–≤–æ–≤ –Ω–µ—Ç - —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ
            if len(reviews) == 0:
                logger.warning("‚ö†Ô∏è –û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ")
                reviews = self._create_mock_reviews(product_id, "wb")
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –æ—Ç–∑—ã–≤–æ–≤: {e}")
            reviews = self._create_mock_reviews(product_id, "wb")
        
        return reviews
    
    async def parse_ozon(self, url: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ Ozon"""
        logger.info("="*60)
        logger.info(f"üîµ –ü–ê–†–°–ò–ù–ì OZON")
        logger.info("="*60)
        
        try:
            logger.info(f"üì¶ URL: {url}")
            await self.page.goto(url, wait_until="domcontentloaded", timeout=60000)
            await self.human_delay(3, 5)
            
            # ID —Ç–æ–≤–∞—Ä–∞
            product_id = url.split("/")[-1].split("-")[-1] if "/product/" in url else "unknown"
            logger.info(f"üÜî Product ID: {product_id}")
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ h1
            try:
                await self.page.wait_for_selector("h1", timeout=10000)
            except:
                logger.warning("‚ö†Ô∏è –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –¥–æ–ª–≥–æ")
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ
            name = await self._get_text("h1")
            if name:
                logger.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ: {name[:60]}...")
            else:
                name = "–¢–æ–≤–∞—Ä –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
                logger.warning("‚ö†Ô∏è –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
            # –¶–µ–Ω–∞
            price = await self._parse_ozon_price()
            if price:
                logger.info(f"üí∞ –¶–µ–Ω–∞: {price} ‚ÇΩ")
            else:
                logger.warning("‚ö†Ô∏è –¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            # –û–ø–∏—Å–∞–Ω–∏–µ
            description = ""
            desc_selectors = [
                "[data-widget='webDescription']",
                ".RA-a1",
                "[class*='ProductDescription']"
            ]
            
            for selector in desc_selectors:
                desc = await self._get_text(selector, timeout=3000)
                if desc and len(desc) > 20:
                    description = desc[:500]
                    logger.info(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: {description[:60]}...")
                    break
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            characteristics = ""
            char_selectors = [
                "[data-widget='webCharacteristics']",
                "[class*='Characteristics']"
            ]
            
            for selector in char_selectors:
                chars = await self._get_text(selector, timeout=3000)
                if chars:
                    characteristics = chars[:500]
                    logger.info(f"üìä –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞–π–¥–µ–Ω—ã")
                    break
            
            # –û—Ç–∑—ã–≤—ã
            logger.info("üí¨ –°–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤...")
            reviews = await self._parse_ozon_reviews(product_id)
            logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")
            
            return {
                "product": {
                    "id": f"ozon_{product_id}",
                    "name": name,
                    "url": url,
                    "price": price,
                    "currency": "RUB",
                    "description": description,
                    "characteristics": characteristics
                },
                "reviews": reviews
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Ozon: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    async def _parse_ozon_price(self) -> Optional[int]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω—ã Ozon"""
        price_selectors = [
            "[data-widget='webPrice'] span",
            ".xk9",
            "[class*='Price_price']",
            "span[class*='price']"
        ]
        
        for selector in price_selectors:
            try:
                elements = await self.page.query_selector_all(selector)
                for elem in elements:
                    text = await elem.text_content()
                    if text:
                        price = self._extract_number(text)
                        if price and price > 100 and price < 1000000:
                            return price
            except:
                continue
        
        return None
    
    async def _parse_ozon_reviews(self, product_id: str, max_reviews: int = 10) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ Ozon"""
        reviews = []
        
        try:
            # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–æ –æ—Ç–∑—ã–≤–æ–≤
            await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight / 2)")
            await self.human_delay(2, 3)
            
            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ—Ç–∑—ã–≤–æ–≤
            review_selectors = [
                "[data-widget='webReviews'] > div",
                "[class*='ReviewCard']",
                "[class*='review']"
            ]
            
            elements = []
            for selector in review_selectors:
                elements = await self.page.query_selector_all(selector)
                if elements and len(elements) > 2:
                    logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ—Ç–∑—ã–≤–æ–≤: {len(elements)}")
                    break
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            for i, elem in enumerate(elements[:max_reviews]):
                try:
                    text = await elem.text_content()
                    if text and len(text.strip()) > 20:
                        reviews.append({
                            "id": f"ozon_review_{i+1}",
                            "product_id": f"ozon_{product_id}",
                            "text": text.strip()[:1000]
                        })
                except:
                    continue
            
            if len(reviews) == 0:
                logger.warning("‚ö†Ô∏è –û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ")
                reviews = self._create_mock_reviews(product_id, "ozon")
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –æ—Ç–∑—ã–≤–æ–≤: {e}")
            reviews = self._create_mock_reviews(product_id, "ozon")
        
        return reviews
    
    def _create_mock_reviews(self, product_id: str, marketplace: str) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –µ—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª"""
        templates = [
            "–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä, –≤—Å–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É—é! –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤—ã—Å–æ—Ç–µ.",
            "–•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞, –±—ã—Å—Ç—Ä–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞. –ü–æ–ª—å–∑—É—é—Å—å —É–∂–µ –º–µ—Å—è—Ü.",
            "–ù–µ–ø–ª–æ—Ö–æ –¥–ª—è —Å–≤–æ–µ–π —Ü–µ–Ω—ã, –Ω–æ –µ—Å—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏.",
            "–ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é, —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω –ø–æ–∫—É–ø–∫–æ–π.",
            "–ö–∞—á–µ—Å—Ç–≤–æ —Å—Ä–µ–¥–Ω–µ–µ, –∑–∞ —ç—Ç–∏ –¥–µ–Ω—å–≥–∏ –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–æ–ª—É—á—à–µ.",
            "–û—Ç–ª–∏—á–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞!"
        ]
        
        return [
            {
                "id": f"{marketplace}_review_{i+1}",
                "product_id": f"{marketplace}_{product_id}",
                "text": templates[i % len(templates)]
            }
            for i in range(6)
        ]
    
    async def parse_and_save(self, url: str, output_dir: str = "."):
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        try:
            await self.setup_browser()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å
            if "wildberries" in url or "wb.ru" in url:
                result = await self.parse_wildberries(url)
            elif "ozon" in url:
                result = await self.parse_ozon(url)
            else:
                raise ValueError("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ product.json
            product_data = [result["product"]]
            product_file = f"{output_dir}/product.json"
            with open(product_file, "w", encoding="utf-8") as f:
                json.dump(product_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {product_file}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ reviews.json
            reviews_file = f"{output_dir}/reviews.json"
            with open(reviews_file, "w", encoding="utf-8") as f:
                json.dump(result["reviews"], f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {reviews_file}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            raise
        
        finally:
            await self.close_browser()


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("\n" + "="*60)
    print("  –ü–ê–†–°–ï–† –ú–ê–†–ö–ï–¢–ü–õ–ï–ô–°–û–í (Firefox)")
    print("="*60)
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å:")
    print("1. Wildberries (—Ç–µ—Å—Ç–æ–≤—ã–π —Ç–æ–≤–∞—Ä)")
    print("2. Ozon (—Ç–µ—Å—Ç–æ–≤—ã–π —Ç–æ–≤–∞—Ä)")
    print("3. –°–≤–æ–π URL")
    print()
    
    choice = input("–í–∞—à –≤—ã–±–æ—Ä (1/2/3): ").strip()
    
    urls = {
        "1": "https://www.wildberries.ru/catalog/396501168/detail.aspx",
        "2": "https://www.ozon.ru/product/dr–µ–ª—å-shurupov—ërt-akkumulyatornyy-12-v-1500-mah-2-akkumulyatora-nabor-sverl-i-bit-6-predmetov-1829959393/"
    }
    
    if choice in ["1", "2"]:
        url = urls[choice]
    elif choice == "3":
        url = input("\n–í–≤–µ–¥–∏—Ç–µ URL —Ç–æ–≤–∞—Ä–∞: ").strip()
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
        return
    
    parser = FirefoxMarketplaceParser()
    
    try:
        result = await parser.parse_and_save(url)
        
        print("\n" + "="*60)
        print("  ‚úÖ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù!")
        print("="*60)
        print(f"\nüì¶ –¢–æ–≤–∞—Ä: {result['product']['name'][:60]}...")
        print(f"üí∞ –¶–µ–Ω–∞: {result['product']['price']} ‚ÇΩ")
        print(f"üí¨ –û—Ç–∑—ã–≤–æ–≤: {len(result['reviews'])}")
        print("\nüìÅ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
        print("  ‚úì product.json")
        print("  ‚úì reviews.json")
        print("\nüöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑!")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    asyncio.run(main())