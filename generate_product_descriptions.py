import os
import json
import re
from typing import Dict, Any, List

from groq import Groq

SYSTEM_PROMPT = """
–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä-–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞–≤–∞—Ç—å —É–±–µ–¥–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –æ–±—Ä–∞—â–∞—é—Ç—Å—è –∫ —è–∑—ã–∫—É, 
—Ü–µ–Ω–Ω–æ—Å—Ç—è–º –∏ "–±–æ–ª—è–º" –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏.
–¢—ã –ø—Ä–µ–≤—Ä–∞—â–∞–µ—à—å —Å—É—Ö–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ —É–±–µ–¥–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π.
""".strip()


def build_user_prompt(product: Dict[str, Any], segment: Dict[str, Any], reviews_insights: List[str]) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç user prompt –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç.
    """
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Å–∞–π—Ç—ã –∏–∑ –æ—Ç–∑—ã–≤–æ–≤
    positive_reviews = [r for r in reviews_insights if '–î–æ—Å—Ç–æ–∏–Ω—Å—Ç–≤–∞' in r][:3]
    negative_reviews = [r for r in reviews_insights if '–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏' in r][:3]
    
    reviews_text = ""
    if positive_reviews or negative_reviews:
        reviews_text = f"""
–ò–Ω—Å–∞–π—Ç—ã –∏–∑ –æ—Ç–∑—ã–≤–æ–≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π:

–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã (–∏–∑ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤):
{chr(10).join(f"- {r[:200]}..." for r in positive_reviews)}

–°–ª–∞–±—ã–µ –º–µ—Å—Ç–∞/–≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è (–∏–∑ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤):
{chr(10).join(f"- {r[:200]}..." for r in negative_reviews)}
"""
    
    return f"""
–†–æ–ª—å:
–¢—ã ‚Äî –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä-–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å 
—É–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –æ–±—Ä–∞—â–∞—é—â–µ–µ—Å—è –∫ —è–∑—ã–∫—É, —Ü–µ–Ω–Ω–æ—Å—Ç—è–º –∏ "–±–æ–ª—è–º" –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ 
—Å–µ–≥–º–µ–Ω—Ç–∞ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏.

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–≤–∞—Ä–µ:

–ù–∞–∑–≤–∞–Ω–∏–µ: {product['name']}
–¶–µ–Ω–∞: {product['price']} {product['currency']}
–¢–µ–∫—É—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {product['description']}
–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {product['characteristics']}

–¶–µ–ª–µ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏—Ç–æ—Ä–∏–∏:

–ù–∞–∑–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞: {segment['name']}
–î–æ–ª—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏: {segment['share_pct_est']}%
–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏: {segment['needs']}
–ë–æ–ª–µ–≤—ã–µ —Ç–æ—á–∫–∏: {segment['pain_points']}
–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {segment['recommended_message']}
{reviews_text}

–ó–∞–¥–∞—á–∞:
–°–æ–∑–¥–∞–π –≥–æ—Ç–æ–≤–æ–µ –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è —ç—Ç–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –∞—É–¥–∏—Ç–æ—Ä–∏–∏.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ (—Å—Ç—Ä–æ–≥–æ –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–π—Å—è):

1. –°–ï–ì–ú–ï–ù–¢-–¶–ï–õ–¨
{segment['name']}

2. –°–¢–†–ê–¢–ï–ì–ò–Ø –¢–ï–ö–°–¢–ê
[1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –∫–∞–∫ –∏ –ø–æ—á–µ–º—É —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –¥–∞–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç]

3. –ó–ê–ì–û–õ–û–í–û–ö (H1)
[–¶–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, 5-10 —Å–ª–æ–≤]

4. –õ–ò–î-–ê–ë–ó–ê–¶ (–ü–û–î–ó–ê–ì–û–õ–û–í–û–ö)
[–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

5. –û–°–ù–û–í–ù–û–ï –û–ü–ò–°–ê–ù–ò–ï

## –ß—Ç–æ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ
[–ü—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤ –≤—ã–≥–æ–¥—ã –¥–ª—è —ç—Ç–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞]

## –†–µ—à–µ–Ω–∏–µ –≤–∞—à–∏—Ö –∑–∞–¥–∞—á
[–û—Ç–≤–µ—Ç—ã –Ω–∞ —Å–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Å–Ω—è—Ç–∏–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –æ—Ç–∑—ã–≤–æ–≤]

## –ß—Ç–æ –≥–æ–≤–æ—Ä—è—Ç –ø–æ–∫—É–ø–∞—Ç–µ–ª–∏
[–°–æ—Ü–∏–∞–ª—å–Ω–æ–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤]

## –ò–¥–µ–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
[–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞]

6. –ü–û–ß–ï–ú–£ –í–´–ë–ò–†–ê–Æ–¢ –ò–ú–ï–ù–ù–û –≠–¢–£ –ú–û–î–ï–õ–¨
- [–ü—É–Ω–∫—Ç 1]
- [–ü—É–Ω–∫—Ç 2]
- [–ü—É–Ω–∫—Ç 3]
- [–ü—É–Ω–∫—Ç 4]

7. –ü–†–ò–ó–´–í –ö –î–ï–ô–°–¢–í–ò–Æ
[–§—Ä–∞–∑–∞ –¥–ª—è –∫–Ω–æ–ø–∫–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –º–æ—Ç–∏–≤–∞—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–∞]

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –û–±—ä—ë–º: 1500-2500 —Å–∏–º–≤–æ–ª–æ–≤
- –¢–æ–Ω: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—É
- –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
- –û–±—Ä–∞—â–∞–π—Å—è –Ω–∞–ø—Ä—è–º—É—é –∫ –±–æ–ª—è–º —Å–µ–≥–º–µ–Ω—Ç–∞
- –í–∫–ª—é—á–∏ —Ü–∏—Ç–∞—Ç—ã –∏–ª–∏ –ø–µ—Ä–µ—Å–∫–∞–∑ –æ—Ç–∑—ã–≤–æ–≤
- –§–æ—Ä–º–∞—Ç: –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞

–ù–∞—á–∏–Ω–∞–π –æ—Ç–≤–µ—Ç —Å—Ä–∞–∑—É —Å —Ä–∞–∑–¥–µ–ª–∞ "1. –°–ï–ì–ú–ï–ù–¢-–¶–ï–õ–¨".
    """.strip()


def load_products(path: str) -> Dict[str, Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç product.json (—Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤) –∏ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å –ø–æ id.
    """
    with open(path, "r", encoding="utf-8") as f:
        items = json.load(f)

    products_by_id: Dict[str, Dict[str, Any]] = {}
    for p in items:
        pid = p["id"]
        products_by_id[pid] = p
    return products_by_id


def load_audience_segments(path: str) -> Dict[str, Any]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç audience_analysis_results.json –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã.
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –º–∞—Å—Å–∏–≤[0].models['qwen/qwen3-32b'].parsed
    """
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    parsed = data[0]['models']['qwen/qwen3-32b']['parsed']
    
    return {
        'product_name': parsed['product_name'],
        'summary': parsed['summary'],
        'segments': parsed['audience_segments'],
        'recommendations': parsed.get('recommendations', []),
        'ab_tests': parsed.get('a_b_test_hypotheses', [])
    }


def load_reviews(path: str) -> List[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç reviews.json –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–æ–≤.
    """
    try:
        with open(path, "r", encoding="utf-8") as f:
            reviews = json.load(f)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–æ–≤
        return [r.get('review', r.get('text', '')) for r in reviews if r.get('review') or r.get('text')]
    except FileNotFoundError:
        print(f"[warning] –§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–µ–∑ –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –æ—Ç–∑—ã–≤–æ–≤.")
        return []


def get_client() -> Groq:
    api_key = os.environ.get("GROQ_API_KEY")
    if not api_key:
        raise RuntimeError(
            "–ù–µ –Ω–∞–π–¥–µ–Ω GROQ_API_KEY. –£—Å—Ç–∞–Ω–æ–≤–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è GROQ_API_KEY —Å–æ —Å–≤–æ–∏–º –∫–ª—é—á–æ–º Groq."
        )
    return Groq(api_key=api_key)


MODELS: List[str] = [
    "qwen/qwen3-32b",
]

THINK_RE = re.compile(r"<think>.*?</think>", re.DOTALL | re.IGNORECASE)

def strip_think_tags(text: str) -> str:
    """
    –£–¥–∞–ª—è–µ—Ç –±–ª–æ–∫–∏ –≤–∏–¥–∞ <think>...</think> –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å.
    """
    return THINK_RE.sub("", text).strip()

def call_model(
    client: Groq, 
    model: str, 
    product: Dict[str, Any], 
    segment: Dict[str, Any],
    reviews_insights: List[str]
) -> tuple:
    """
    –í—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ Groq –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤).
    """
    user_prompt = build_user_prompt(product, segment, reviews_insights)

    completion = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.7,
        max_tokens=3000,
    )

    content = completion.choices[0].message.content or ""
    
    # –ü–æ–¥—Å—á–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    tokens_used = completion.usage.total_tokens if hasattr(completion, 'usage') else 0
    
    return content, tokens_used


def save_as_markdown(results: List[Dict[str, Any]], product_name: str, output_path: str):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫—Ä–∞—Å–∏–≤–æ–º Markdown —Ñ–æ—Ä–º–∞—Ç–µ.
    """
    markdown_path = output_path.replace('.json', '.md')
    
    with open(markdown_path, 'w', encoding='utf-8') as f:
        f.write(f"# –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞\n\n")
        f.write(f"**–¢–æ–≤–∞—Ä:** {product_name}\n\n")
        f.write("---\n\n")
        
        for result in results:
            f.write(f"## –°–µ–≥–º–µ–Ω—Ç: {result['segment_name']} ({result['segment_share']}% –∞—É–¥–∏—Ç–æ—Ä–∏–∏)\n\n")
            f.write(f"**–ú–æ–¥–µ–ª—å:** {result['model']}\n")
            f.write(f"**–¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ:** {result['tokens_used']}\n\n")
            f.write(result['description'])
            f.write("\n\n---\n\n")
    
    print(f"[info] Markdown –≤–µ—Ä—Å–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {markdown_path}")


def main():
    print("\n" + "="*80)
    print("  üìù –ì–ï–ù–ï–†–ê–¢–û–† –ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–• –û–ü–ò–°–ê–ù–ò–ô –¢–û–í–ê–†–ê")
    print("="*80)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n[info] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    try:
        products = load_products("product.json")
        audience_data = load_audience_segments("audience_analysis_results.json")
        reviews_insights = load_reviews("reviews.json")
        
        print(f"[info] –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
        print(f"[info] –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(audience_data['segments'])}")
        print(f"[info] –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews_insights)}")
        
    except FileNotFoundError as e:
        print(f"\n[error] –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {e}")
        print("\nüí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã:")
        print("  - product.json")
        print("  - audience_analysis_results.json")
        print("  - reviews.json (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —Ç–æ–≤–∞—Ä (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö)
    product_id = list(products.keys())[0]
    product = products[product_id]
    
    print(f"\n[info] –¢–æ–≤–∞—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {product['name']}")
    print(f"[info] –¶–µ–Ω–∞: {product['price']} {product['currency']}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
    client = get_client()
    
    results: List[Dict[str, Any]] = []
    total_tokens = 0
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
    for idx, segment in enumerate(audience_data['segments'], 1):
        print("\n" + "="*80)
        print(f"[{idx}/{len(audience_data['segments'])}] –°–µ–≥–º–µ–Ω—Ç: {segment['name']}")
        print("-"*80)
        
        for model in MODELS:
            print(f"[info] –ú–æ–¥–µ–ª—å: {model}")
            
            try:
                description, tokens_used = call_model(
                    client, 
                    model, 
                    product, 
                    segment,
                    reviews_insights
                )
                
                total_tokens += tokens_used
                
                print(f"[ok] –û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ! –¢–æ–∫–µ–Ω–æ–≤: {tokens_used}")
                print(f"[info] –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(description)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                results.append({
                    "segment_name": segment['name'],
                    "segment_share": segment['share_pct_est'],
                    "description": description,
                    "model": model,
                    "tokens_used": tokens_used
                })
                
            except Exception as e:
                print(f"[error] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                import traceback
                traceback.print_exc()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    out_path = "product_descriptions.json"
    
    output_data = {
        "product": {
            "id": product['id'],
            "name": product['name'],
            "price": product['price'],
            "currency": product['currency']
        },
        "descriptions": results,
        "metadata": {
            "total_segments": len(results),
            "total_tokens": total_tokens,
            "models_used": MODELS
        }
    }
    
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print("\n" + "="*80)
    print("  ‚úÖ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("="*80)
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  - –°–æ–∑–¥–∞–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–π: {len(results)}")
    print(f"  - –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")
    print(f"\nüíæ –§–∞–π–ª—ã:")
    print(f"  - JSON: {out_path}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Markdown
    save_as_markdown(results, product['name'], out_path)
    
    print("\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞—Ö!")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()